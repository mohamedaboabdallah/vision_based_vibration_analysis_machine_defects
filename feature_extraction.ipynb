{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673a86f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Bearing_fault: 100%|██████████| 36/36 [03:46<00:00,  6.29s/it]\n",
      "Processing Bearing_fault:  39%|███▉      | 28/72 [02:24<03:46,  5.15s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 132\u001b[0m\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m video_paths:\n\u001b[0;32m    130\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m--> 132\u001b[0m     segment_data \u001b[38;5;241m=\u001b[39m \u001b[43mextract_features_for_videos\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_paths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    133\u001b[0m     all_data\u001b[38;5;241m.\u001b[39mextend(segment_data)\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m all_data:\n",
      "Cell \u001b[1;32mIn[3], line 99\u001b[0m, in \u001b[0;36mextract_features_for_videos\u001b[1;34m(video_paths, state)\u001b[0m\n\u001b[0;32m     96\u001b[0m view \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mangle\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mangle\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m video_name\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfront\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;66;03m# Feature extraction\u001b[39;00m\n\u001b[1;32m---> 99\u001b[0m mean_flow, std_flow \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_optical_flow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    100\u001b[0m edge_ratio_value \u001b[38;5;241m=\u001b[39m calculate_edge_ratio(video_path)\n\u001b[0;32m    101\u001b[0m keypoint_count \u001b[38;5;241m=\u001b[39m count_keypoints(video_path)\n",
      "Cell \u001b[1;32mIn[3], line 25\u001b[0m, in \u001b[0;36mcalculate_optical_flow\u001b[1;34m(video_path)\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     24\u001b[0m gray \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(frame, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[1;32m---> 25\u001b[0m flow \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalcOpticalFlowFarneback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprev_gray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m                                    \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m flow_values\u001b[38;5;241m.\u001b[39mappend(flow)\n\u001b[0;32m     28\u001b[0m prev_gray \u001b[38;5;241m=\u001b[39m gray\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "# Frame-wise optical flow\n",
    "def calculate_optical_flow(prev_gray, gray):\n",
    "    flow = cv2.calcOpticalFlowFarneback(prev_gray, gray, None,\n",
    "                                        0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    return np.mean(flow), np.std(flow)\n",
    "\n",
    "# Edge ratio per frame\n",
    "def calculate_edge_ratio(gray):\n",
    "    edges = cv2.Canny(gray, 100, 200)\n",
    "    edge_pixels = np.count_nonzero(edges)\n",
    "    total_pixels = gray.shape[0] * gray.shape[1]\n",
    "    return edge_pixels / total_pixels if total_pixels != 0 else 0\n",
    "\n",
    "# Keypoints per frame\n",
    "sift = cv2.SIFT_create()\n",
    "def count_keypoints(gray):\n",
    "    kp, _ = sift.detectAndCompute(gray, None)\n",
    "    return len(kp)\n",
    "\n",
    "# FFT peak per frame\n",
    "def extract_fft_peak(gray):\n",
    "    fft = np.fft.fft2(gray)\n",
    "    fft_shift = np.fft.fftshift(fft)\n",
    "    fft_magnitude = np.abs(fft_shift)\n",
    "    return np.max(fft_magnitude)\n",
    "\n",
    "# Extract per-frame features for a video\n",
    "def extract_per_frame_features(video_path, state):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    video_name = os.path.basename(video_path)\n",
    "    view = 'angle' if 'angle' in video_name.lower() else 'front'\n",
    "\n",
    "    frame_index = 0\n",
    "    ret, prev_frame = cap.read()\n",
    "    if not ret:\n",
    "        cap.release()\n",
    "        return []\n",
    "\n",
    "    prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "    data = []\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        mean_flow, std_flow = calculate_optical_flow(prev_gray, gray)\n",
    "        edge_ratio = calculate_edge_ratio(gray)\n",
    "        keypoints = count_keypoints(gray)\n",
    "        fft_peak = extract_fft_peak(gray)\n",
    "\n",
    "        data.append([\n",
    "            video_name, frame_index, mean_flow, std_flow, edge_ratio,\n",
    "            keypoints, fft_peak, view, state\n",
    "        ])\n",
    "\n",
    "        prev_gray = gray\n",
    "        frame_index += 1\n",
    "\n",
    "    cap.release()\n",
    "    return data\n",
    "\n",
    "# Directory setup\n",
    "base_dir = Path('evm_segmented_videos')\n",
    "output_dir = Path('Datasets')\n",
    "states = ['Bearing_fault', 'Normal_state', 'Unbalance_weight']\n",
    "segments = ['segmented_5', 'segmented_5_overlap', 'segmented_10',\n",
    "            'segmented_10_overlap', 'segmented_15', 'segmented_15_overlap']\n",
    "\n",
    "for state in states:\n",
    "    (output_dir / state).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Process each state\n",
    "for state in states:\n",
    "    all_data = []\n",
    "    for segment in segments:\n",
    "        segment_path = base_dir / state / segment\n",
    "        video_paths = glob(str(segment_path / \"*.avi\"))\n",
    "        if not video_paths:\n",
    "            continue\n",
    "\n",
    "        for video_path in tqdm(video_paths, desc=f\"{state} - {segment}\"):\n",
    "            frame_data = extract_per_frame_features(video_path, state)\n",
    "            all_data.extend(frame_data)\n",
    "\n",
    "    if all_data:\n",
    "        columns = ['video_name', 'frame_index', 'mean_flow', 'std_flow',\n",
    "                   'edge_ratio', 'keypoint_count', 'fft_peak', 'view', 'state']\n",
    "        df = pd.DataFrame(all_data, columns=columns)\n",
    "        output_csv = output_dir / state / f\"{state}_framewise_features.csv\"\n",
    "        df.to_csv(output_csv, index=False)\n",
    "\n",
    "print(\"✅ Frame-wise feature extraction completed!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
