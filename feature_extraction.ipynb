{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673a86f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "# Function to calculate optical flow\n",
    "def calculate_optical_flow(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    ret, prev_frame = cap.read()\n",
    "    prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    flow_values = []\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        flow = cv2.calcOpticalFlowFarneback(prev_gray, gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "        flow_values.append(flow)\n",
    "        prev_gray = gray\n",
    "    \n",
    "    cap.release()\n",
    "    flow_values = np.array(flow_values)\n",
    "    return np.mean(flow_values), np.std(flow_values)\n",
    "\n",
    "# Function to calculate edge ratio (simplified as the ratio of edge pixels to total pixels)\n",
    "def calculate_edge_ratio(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    ret, frame = cap.read()\n",
    "    edge_pixels = 0\n",
    "    total_pixels = 0\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        edges = cv2.Canny(frame, 100, 200)\n",
    "        edge_pixels += np.sum(edges)  # Counting edge pixels\n",
    "        total_pixels += frame.size  # Counting total pixels\n",
    "    \n",
    "    cap.release()\n",
    "    return edge_pixels / total_pixels\n",
    "\n",
    "# Function to count keypoints (using SIFT)\n",
    "def count_keypoints(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    ret, frame = cap.read()\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints = 0\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        kp, _ = sift.detectAndCompute(gray, None)\n",
    "        keypoints += len(kp)  # Count number of keypoints\n",
    "    \n",
    "    cap.release()\n",
    "    return keypoints\n",
    "\n",
    "# Function to extract FFT peaks (example: take the peak values of frequency components)\n",
    "def extract_fft_peaks(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    fft_peaks = []\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        fft = np.fft.fft2(gray)\n",
    "        fft_abs = np.abs(fft)\n",
    "        fft_peaks.append(np.max(fft_abs))  # Max peak in FFT\n",
    "    \n",
    "    cap.release()\n",
    "    return fft_peaks[:3]  # Return top 3 peaks\n",
    "\n",
    "# Main feature extraction function\n",
    "def extract_features_for_videos(video_paths, state, segment):\n",
    "    data = []\n",
    "    for video_path in tqdm(video_paths):\n",
    "        video_name = os.path.basename(video_path)\n",
    "        \n",
    "        # Extract features\n",
    "        mean_flow, std_flow = calculate_optical_flow(video_path)\n",
    "        edge_ratio_value = calculate_edge_ratio(video_path)\n",
    "        keypoint_count = count_keypoints(video_path)\n",
    "        fft_peaks = extract_fft_peaks(video_path)\n",
    "        \n",
    "        # Add row for this video\n",
    "        data.append([\n",
    "            video_name, mean_flow, std_flow, edge_ratio_value, keypoint_count, \n",
    "            *fft_peaks, state, segment\n",
    "        ])\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Directory structure setup\n",
    "base_dir = Path('evm_segmented_videos')  # Base directory where your video segments are located\n",
    "output_dir = Path('Datasets')  # Directory where final datasets will be saved\n",
    "\n",
    "# Create subdirectories for each state\n",
    "states = ['Bearing_fault', 'Normal_state', 'Unbalance_weight']\n",
    "for state in states:\n",
    "    state_dir = output_dir / state\n",
    "    state_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Loop through each state and segment type to process videos and generate CSVs\n",
    "for state in states:\n",
    "    state_path = base_dir / state\n",
    "    for segment in ['segmented_5', 'segmented_5_overlap', 'segmented_10', 'segmented_10_overlap', 'segmented_15', 'segmented_15_overlap']:\n",
    "        segment_path = state_path / segment\n",
    "        video_paths = glob(str(segment_path / \"*.avi\"))\n",
    "        \n",
    "        # Extract features for all videos in this segment and state\n",
    "        data = extract_features_for_videos(video_paths, state, segment)\n",
    "        \n",
    "        # Create DataFrame from extracted data\n",
    "        columns = ['video_name', 'mean_flow', 'std_flow', 'edge_ratio', 'keypoint_count', 'fft_peak1', 'fft_peak2', 'fft_peak3', 'state', 'segment']\n",
    "        df = pd.DataFrame(data, columns=columns)\n",
    "        \n",
    "        # Save DataFrame to CSV in the appropriate directory\n",
    "        output_csv = output_dir / state / f\"{segment}_combined_features.csv\"\n",
    "        df.to_csv(output_csv, index=False)\n",
    "\n",
    "print(\"Feature extraction and CSV generation completed!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
