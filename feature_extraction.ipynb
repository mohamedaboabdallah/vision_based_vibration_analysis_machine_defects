{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "673a86f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "119eadcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Feature extraction functions (modified for per-frame calculations)\n",
    "def calculate_optical_flow_per_frame(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    flow_values = []\n",
    "\n",
    "    ret, prev_frame = cap.read()\n",
    "    if not ret:\n",
    "        cap.release()\n",
    "        return []\n",
    "\n",
    "    prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        flow = cv2.calcOpticalFlowFarneback(prev_gray, gray, None,\n",
    "                                            0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "        mean_flow = np.mean(flow)\n",
    "        std_flow = np.std(flow)\n",
    "        flow_values.append((mean_flow, std_flow))\n",
    "        prev_gray = gray\n",
    "    \n",
    "    cap.release()\n",
    "    return flow_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "69f3b4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_edge_ratio_per_frame(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    edge_ratios = []\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        edges = cv2.Canny(frame, 100, 200)\n",
    "        edge_pixels = np.count_nonzero(edges)\n",
    "        total_pixels = frame.shape[0] * frame.shape[1]\n",
    "        edge_ratios.append(edge_pixels / total_pixels if total_pixels != 0 else 0)\n",
    "    \n",
    "    cap.release()\n",
    "    return edge_ratios\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "63e58b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def count_keypoints_per_frame(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints_per_frame = []\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        kp, _ = sift.detectAndCompute(gray, None)\n",
    "        keypoints_per_frame.append(len(kp))\n",
    "    \n",
    "    cap.release()\n",
    "    return keypoints_per_frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d79f3972",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def extract_fft_peaks_per_frame(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    peak_values = []\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        fft = np.fft.fft2(gray)\n",
    "        fft_shift = np.fft.fftshift(fft)\n",
    "        fft_magnitude = np.abs(fft_shift)\n",
    "        peak_values.append(np.max(fft_magnitude))\n",
    "    \n",
    "    cap.release()\n",
    "    return peak_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bec75858",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_for_videos(video_paths, state, segment):\n",
    "    data = []\n",
    "    for video_path in tqdm(video_paths, desc=f\"Processing {state} - {segment}\"):\n",
    "        video_name = os.path.basename(video_path)\n",
    "        \n",
    "        # Determine view from filename\n",
    "        view = 'angle' if 'angle' in video_name.lower() else 'front'\n",
    "\n",
    "        # Extract per-frame features\n",
    "        flow_values = calculate_optical_flow_per_frame(video_path)\n",
    "        edge_ratios = calculate_edge_ratio_per_frame(video_path)\n",
    "        keypoint_counts = count_keypoints_per_frame(video_path)\n",
    "        fft_peaks = extract_fft_peaks_per_frame(video_path)\n",
    "\n",
    "        # Ensure all feature lists have the same length\n",
    "        max_frames = max(len(flow_values), len(edge_ratios), len(keypoint_counts), len(fft_peaks))\n",
    "        \n",
    "        # Pad feature lists if they are shorter than the longest list\n",
    "        flow_values.extend([(0, 0)] * (max_frames - len(flow_values)))\n",
    "        edge_ratios.extend([0] * (max_frames - len(edge_ratios)))\n",
    "        keypoint_counts.extend([0] * (max_frames - len(keypoint_counts)))\n",
    "        fft_peaks.extend([0] * (max_frames - len(fft_peaks)))\n",
    "\n",
    "        # Add data for each frame\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        frame_index = 0  # Start at frame 0\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            # Unpack flow values for the current frame\n",
    "            mean_flow, std_flow = flow_values[frame_index]\n",
    "            \n",
    "            # Extract features for the current frame\n",
    "            data.append([video_name, frame_index, mean_flow, std_flow, \n",
    "                         edge_ratios[frame_index], keypoint_counts[frame_index], fft_peaks[frame_index], view, state])\n",
    "            frame_index += 1\n",
    "        cap.release()\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5d1526",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Bearing_fault - segmented_5: 100%|██████████| 36/36 [01:39<00:00,  2.78s/it]\n",
      "Processing Bearing_fault - segmented_5_overlap:  64%|██████▍   | 46/72 [02:32<01:10,  2.70s/it]"
     ]
    }
   ],
   "source": [
    "\n",
    "# Directory setup\n",
    "base_dir = Path('evm_segmented_videos')\n",
    "output_dir = Path('Datasets')\n",
    "states = ['Bearing_fault', 'Normal_state', 'Unbalance_weight']\n",
    "segments = ['segmented_5', 'segmented_5_overlap', 'segmented_10',\n",
    "            'segmented_10_overlap', 'segmented_15', 'segmented_15_overlap']\n",
    "\n",
    "for state in states:\n",
    "    (output_dir / state).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Process and generate CSVs\n",
    "for state in states:\n",
    "    for segment in segments:\n",
    "        segment_path = base_dir / state / segment\n",
    "        video_paths = glob(str(segment_path / \"*.avi\"))\n",
    "        if not video_paths:\n",
    "            continue\n",
    "        segment_data = extract_features_for_videos(video_paths, state, segment)\n",
    "        # Ensure the directory exists before saving\n",
    "        segment_output_dir = output_dir / state / segment\n",
    "        segment_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        if segment_data:\n",
    "            columns = ['video_name', 'frame_index', 'mean_flow', 'std_flow', 'edge_ratio', 'keypoint_count',\n",
    "                       'fft_peak', 'view', 'state']\n",
    "            df = pd.DataFrame(segment_data, columns=columns)\n",
    "            output_csv = segment_output_dir / f\"{segment}_features.csv\"\n",
    "            df.to_csv(output_csv, index=False)\n",
    "\n",
    "print(\"✅ Feature extraction and CSV generation for each time slice completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
