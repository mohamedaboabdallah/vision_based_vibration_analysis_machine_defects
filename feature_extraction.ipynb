{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "673a86f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "119eadcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Feature extraction functions (unchanged)\n",
    "def calculate_optical_flow(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    flow_values = []\n",
    "\n",
    "    ret, prev_frame = cap.read()\n",
    "    if not ret:\n",
    "        cap.release()\n",
    "        return 0, 0\n",
    "\n",
    "    prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        flow = cv2.calcOpticalFlowFarneback(prev_gray, gray, None,\n",
    "                                            0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "        flow_values.append(flow)\n",
    "        prev_gray = gray\n",
    "    \n",
    "    cap.release()\n",
    "    flow_values = np.array(flow_values)\n",
    "    return np.mean(flow_values), np.std(flow_values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69f3b4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_edge_ratio(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    edge_pixels = 0\n",
    "    total_pixels = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        edges = cv2.Canny(frame, 100, 200)\n",
    "        edge_pixels += np.count_nonzero(edges)\n",
    "        total_pixels += frame.shape[0] * frame.shape[1]\n",
    "    \n",
    "    cap.release()\n",
    "    return edge_pixels / total_pixels if total_pixels != 0 else 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63e58b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def count_keypoints(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoint_count = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        kp, _ = sift.detectAndCompute(gray, None)\n",
    "        keypoint_count += len(kp)\n",
    "    \n",
    "    cap.release()\n",
    "    return keypoint_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d79f3972",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def extract_fft_peaks(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    peak_values = []\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        fft = np.fft.fft2(gray)\n",
    "        fft_shift = np.fft.fftshift(fft)\n",
    "        fft_magnitude = np.abs(fft_shift)\n",
    "        peak_values.append(np.max(fft_magnitude))\n",
    "    \n",
    "    cap.release()\n",
    "    top_peaks = sorted(peak_values, reverse=True)[:3]\n",
    "    while len(top_peaks) < 3:\n",
    "        top_peaks.append(0)\n",
    "    return top_peaks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bec75858",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def extract_features_for_videos(video_paths, state, segment):\n",
    "    data = []\n",
    "    for video_path in tqdm(video_paths, desc=f\"Processing {state} - {segment}\"):\n",
    "        video_name = os.path.basename(video_path)\n",
    "        \n",
    "        # Determine view from filename\n",
    "        view = 'angle' if 'angle' in video_name.lower() else 'front'\n",
    "\n",
    "        # Feature extraction\n",
    "        mean_flow, std_flow = calculate_optical_flow(video_path)\n",
    "        edge_ratio_value = calculate_edge_ratio(video_path)\n",
    "        keypoint_count = count_keypoints(video_path)\n",
    "        fft_peaks = extract_fft_peaks(video_path)\n",
    "\n",
    "        # Add data for each frame in the segment\n",
    "        frame_index = 0  # Start at frame 0\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            # Extract features per frame\n",
    "            data.append([video_name, frame_index, mean_flow, std_flow, edge_ratio_value, keypoint_count,\n",
    "                         *fft_peaks, view, state])\n",
    "            frame_index += 1\n",
    "        cap.release()\n",
    "    \n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c5d1526",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Bearing_fault - segmented_5: 100%|██████████| 36/36 [01:35<00:00,  2.65s/it]\n",
      "Processing Bearing_fault - segmented_5_overlap: 100%|██████████| 72/72 [03:27<00:00,  2.89s/it]\n",
      "Processing Bearing_fault - segmented_10: 100%|██████████| 18/18 [01:57<00:00,  6.55s/it]\n",
      "Processing Bearing_fault - segmented_10_overlap: 100%|██████████| 34/34 [05:25<00:00,  9.57s/it]\n",
      "Processing Bearing_fault - segmented_15: 100%|██████████| 12/12 [03:44<00:00, 18.71s/it]\n",
      "Processing Bearing_fault - segmented_15_overlap: 100%|██████████| 22/22 [04:57<00:00, 13.50s/it]\n",
      "Processing Normal_state - segmented_5: 100%|██████████| 36/36 [02:27<00:00,  4.09s/it]\n",
      "Processing Normal_state - segmented_5_overlap: 100%|██████████| 72/72 [03:57<00:00,  3.30s/it]\n",
      "Processing Normal_state - segmented_10: 100%|██████████| 18/18 [02:01<00:00,  6.78s/it]\n",
      "Processing Normal_state - segmented_10_overlap: 100%|██████████| 34/34 [03:48<00:00,  6.71s/it]\n",
      "Processing Normal_state - segmented_15: 100%|██████████| 12/12 [01:57<00:00,  9.81s/it]\n",
      "Processing Normal_state - segmented_15_overlap: 100%|██████████| 22/22 [04:00<00:00, 10.91s/it]\n",
      "Processing Unbalance_weight - segmented_5: 100%|██████████| 36/36 [02:01<00:00,  3.37s/it]\n",
      "Processing Unbalance_weight - segmented_5_overlap: 100%|██████████| 72/72 [03:42<00:00,  3.09s/it]\n",
      "Processing Unbalance_weight - segmented_10: 100%|██████████| 18/18 [01:42<00:00,  5.67s/it]\n",
      "Processing Unbalance_weight - segmented_10_overlap: 100%|██████████| 34/34 [03:07<00:00,  5.52s/it]\n",
      "Processing Unbalance_weight - segmented_15: 100%|██████████| 12/12 [01:46<00:00,  8.89s/it]\n",
      "Processing Unbalance_weight - segmented_15_overlap: 100%|██████████| 22/22 [02:59<00:00,  8.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Feature extraction and CSV generation for each time slice completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Directory setup\n",
    "base_dir = Path('evm_segmented_videos')\n",
    "output_dir = Path('Datasets')\n",
    "states = ['Bearing_fault', 'Normal_state', 'Unbalance_weight']\n",
    "segments = ['segmented_5', 'segmented_5_overlap', 'segmented_10',\n",
    "            'segmented_10_overlap', 'segmented_15', 'segmented_15_overlap']\n",
    "\n",
    "for state in states:\n",
    "    (output_dir / state).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Process and generate CSVs\n",
    "for state in states:\n",
    "    for segment in segments:\n",
    "        segment_path = base_dir / state / segment\n",
    "        video_paths = glob(str(segment_path / \"*.avi\"))\n",
    "        if not video_paths:\n",
    "            continue\n",
    "        \n",
    "        # Extract features for all frames in this segment\n",
    "        segment_data = extract_features_for_videos(video_paths, state, segment)\n",
    "        \n",
    "        # Ensure the directory exists before saving\n",
    "        segment_output_dir = output_dir / state / segment\n",
    "        segment_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Save the segment's data to CSV\n",
    "        if segment_data:\n",
    "            columns = ['video_name', 'frame_index', 'mean_flow', 'std_flow', 'edge_ratio', 'keypoint_count',\n",
    "                       'fft_peak1', 'fft_peak2', 'fft_peak3', 'view', 'state']\n",
    "            df = pd.DataFrame(segment_data, columns=columns)\n",
    "            output_csv = segment_output_dir / f\"{segment}_features.csv\"\n",
    "            df.to_csv(output_csv, index=False)\n",
    "\n",
    "print(\"✅ Feature extraction and CSV generation for each time slice completed!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
