{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "673a86f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path  \n",
    "from scipy import stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51d115a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_segment_parameters(segment_name):\n",
    "    \"\"\"Extract duration and overlap status from segment folder name\"\"\"\n",
    "    parts = segment_name.split('_')\n",
    "    duration = int(parts[1])\n",
    "    overlap = 'overlap' in segment_name\n",
    "    return duration, overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8df47be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_frames(video_path):\n",
    "    \"\"\"Load and preprocess video frames\"\"\"\n",
    "    cap = cv2.VideoCapture(str(video_path))\n",
    "    frames = []\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        frames.append(gray)\n",
    "    cap.release()\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d2997a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_motion_features(frames, window_seconds, fps):\n",
    "    \"\"\"Calculate comprehensive motion features with temporal window\"\"\"\n",
    "    window_frames = int(window_seconds * fps)\n",
    "    flow_magnitudes = []\n",
    "    flow_orientations = []\n",
    "    temporal_gradients = []\n",
    "    \n",
    "    prev_frame = frames[0]\n",
    "    for i in range(len(frames)):\n",
    "        # Optical flow features\n",
    "        ref_idx = max(0, i - window_frames)\n",
    "        flow = cv2.calcOpticalFlowFarneback(\n",
    "            frames[ref_idx], frames[i], None, 0.5, 3, 15, 3, 5, 1.2, 0\n",
    "        )\n",
    "        magnitude = np.sqrt(flow[...,0]**2 + flow[...,1]**2)\n",
    "        orientation = np.arctan2(flow[...,1], flow[...,0])\n",
    "        \n",
    "        flow_magnitudes.extend(magnitude.flatten())\n",
    "        flow_orientations.extend(orientation.flatten())\n",
    "        \n",
    "        # Temporal gradient features\n",
    "        if i > 0:\n",
    "            diff = cv2.absdiff(frames[i], frames[i-1])\n",
    "            temporal_gradients.append(np.mean(diff))\n",
    "    \n",
    "    # Optical flow statistics\n",
    "    flow_mean = np.nanmean(flow_magnitudes) if flow_magnitudes else 0\n",
    "    flow_std = np.nanstd(flow_magnitudes) if flow_magnitudes else 0\n",
    "    \n",
    "    # Orientation circular statistics\n",
    "    orientation_sin = np.mean(np.sin(flow_orientations))\n",
    "    orientation_cos = np.mean(np.cos(flow_orientations))\n",
    "    orientation_mean = np.arctan2(orientation_sin, orientation_cos)\n",
    "    orientation_std = np.sqrt(-2 * np.log(np.hypot(orientation_sin, orientation_cos)))\n",
    "    \n",
    "    # Temporal gradient statistics\n",
    "    grad_mean = np.mean(temporal_gradients) if temporal_gradients else 0\n",
    "    grad_std = np.std(temporal_gradients) if temporal_gradients else 0\n",
    "    \n",
    "    # Frequency analysis\n",
    "    if len(flow_magnitudes) > 1:\n",
    "        fft = np.fft.fft(flow_magnitudes)\n",
    "        fft_freq = np.fft.fftfreq(len(fft))\n",
    "        dominant_freq = np.abs(fft_freq[np.argmax(np.abs(fft[1:])) + 1])\n",
    "    else:\n",
    "        dominant_freq = 0\n",
    "    \n",
    "    return {\n",
    "        # Basic flow features\n",
    "        'flow_mean': flow_mean,\n",
    "        'flow_std': flow_std,\n",
    "        'flow_max': np.max(flow_magnitudes) if flow_magnitudes else 0,\n",
    "        \n",
    "        # Orientation features\n",
    "        'orientation_mean': orientation_mean,\n",
    "        'orientation_std': orientation_std,\n",
    "        \n",
    "        # Temporal dynamics\n",
    "        'temporal_grad_mean': grad_mean,\n",
    "        'temporal_grad_std': grad_std,\n",
    "        'temporal_grad_max': np.max(temporal_gradients) if temporal_gradients else 0,\n",
    "        \n",
    "        # Frequency analysis\n",
    "        'dominant_freq': dominant_freq,\n",
    "        \n",
    "        # Motion complexity\n",
    "        'flow_entropy': stats.entropy(np.histogram(flow_magnitudes, bins=20)[0]) \n",
    "                        if flow_magnitudes else 0,\n",
    "        'motion_consistency': flow_std / (flow_mean + 1e-6)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "119eadcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_segment_features(video_path, segment_name):\n",
    "    \"\"\"Main feature extraction function\"\"\"\n",
    "    # Get segment parameters\n",
    "    duration_seconds, is_overlap = get_segment_parameters(segment_name)\n",
    "    \n",
    "    # Load video data\n",
    "    frames = load_frames(video_path)\n",
    "    if not frames:\n",
    "        return None\n",
    "    \n",
    "    # Calculate actual FPS\n",
    "    fps = len(frames) / duration_seconds\n",
    "    \n",
    "    # Calculate motion features\n",
    "    motion_features = calculate_motion_features(frames, duration_seconds, fps)\n",
    "    \n",
    "    # Create feature dictionary\n",
    "    features = {\n",
    "        'video_name': video_path.name,\n",
    "        'state': Path(video_path).parent.parent.name,\n",
    "        'view': 'angle' if 'angle' in video_path.name.lower() else 'front',\n",
    "        'segment_duration': duration_seconds,\n",
    "        'is_overlap': is_overlap,\n",
    "        'total_frames': len(frames),\n",
    "        'actual_fps': fps,\n",
    "        **motion_features\n",
    "    }\n",
    "    \n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69f3b4e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bearing_fault - segmented_10: 100%|██████████| 18/18 [02:16<00:00,  7.56s/it]\n",
      "Bearing_fault - segmented_10_overlap: 100%|██████████| 34/34 [04:36<00:00,  8.13s/it]\n",
      "Bearing_fault - segmented_15: 100%|██████████| 12/12 [02:23<00:00, 11.99s/it]\n",
      "Bearing_fault - segmented_15_overlap: 100%|██████████| 22/22 [05:41<00:00, 15.54s/it]\n",
      "Bearing_fault - segmented_5: 100%|██████████| 36/36 [03:03<00:00,  5.10s/it]\n",
      "Bearing_fault - segmented_5_overlap: 100%|██████████| 72/72 [06:27<00:00,  5.38s/it]\n",
      "Normal_state - segmented_10: 100%|██████████| 18/18 [03:11<00:00, 10.61s/it]\n",
      "Normal_state - segmented_10_overlap: 100%|██████████| 34/34 [06:14<00:00, 11.00s/it]\n",
      "Normal_state - segmented_15: 100%|██████████| 12/12 [02:43<00:00, 13.64s/it]\n",
      "Normal_state - segmented_15_overlap: 100%|██████████| 22/22 [04:25<00:00, 12.05s/it]\n",
      "Normal_state - segmented_5: 100%|██████████| 36/36 [02:20<00:00,  3.90s/it]\n",
      "Normal_state - segmented_5_overlap: 100%|██████████| 72/72 [04:42<00:00,  3.92s/it]\n",
      "Unbalance_weight - segmented_10: 100%|██████████| 18/18 [02:16<00:00,  7.58s/it]\n",
      "Unbalance_weight - segmented_10_overlap: 100%|██████████| 34/34 [05:10<00:00,  9.13s/it]\n",
      "Unbalance_weight - segmented_15: 100%|██████████| 12/12 [02:46<00:00, 13.88s/it]\n",
      "Unbalance_weight - segmented_15_overlap: 100%|██████████| 22/22 [05:00<00:00, 13.66s/it]\n",
      "Unbalance_weight - segmented_5: 100%|██████████| 36/36 [03:07<00:00,  5.21s/it]\n",
      "Unbalance_weight - segmented_5_overlap: 100%|██████████| 72/72 [06:34<00:00,  5.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Features saved to optical_flow_features.csv\n"
     ]
    }
   ],
   "source": [
    "def process_all_segments(base_dir, output_path):\n",
    "    \"\"\"Process all videos in directory structure\"\"\"\n",
    "    base_path = Path(base_dir)\n",
    "    all_features = []\n",
    "    \n",
    "    # Iterate through all state directories\n",
    "    for state_dir in base_path.iterdir():\n",
    "        if not state_dir.is_dir():\n",
    "            continue\n",
    "            \n",
    "        # Process each segment type\n",
    "        for segment_dir in state_dir.iterdir():\n",
    "            if not segment_dir.is_dir():\n",
    "                continue\n",
    "                \n",
    "            segment_name = segment_dir.name\n",
    "            video_files = list(segment_dir.glob('*.avi'))\n",
    "            \n",
    "            # Process videos with progress bar\n",
    "            for video_path in tqdm(video_files, \n",
    "                                 desc=f\"{state_dir.name} - {segment_name}\"):\n",
    "                features = extract_segment_features(video_path, segment_name)\n",
    "                if features:\n",
    "                    all_features.append(features)\n",
    "    \n",
    "    # Create DataFrame and save\n",
    "    if all_features:\n",
    "        df = pd.DataFrame(all_features)\n",
    "        df.to_csv(output_path, index=False)\n",
    "        print(f\"✅ Features saved to {output_path}\")\n",
    "    else:\n",
    "        print(\"⚠️ No features extracted - check input data\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Configuration\n",
    "    BASE_DIR = \"evm_segmented_videos\"\n",
    "    OUTPUT_CSV = \"optical_flow_features.csv\"\n",
    "    \n",
    "    # Run processing\n",
    "    process_all_segments(BASE_DIR, OUTPUT_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8cbfc315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 5s.csv with 108 samples\n",
      "Created 5s_overlap.csv with 216 samples\n",
      "Created 10s.csv with 54 samples\n",
      "Created 10s_overlap.csv with 102 samples\n",
      "Created 15s.csv with 36 samples\n",
      "Created 15s_overlap.csv with 66 samples\n"
     ]
    }
   ],
   "source": [
    "def create_segmented_datasets():\n",
    "    \"\"\"Split main dataset into duration-specific subsets\"\"\"\n",
    "    df = pd.read_csv('optical_flow_features.csv')\n",
    "    os.makedirs('final_dataset_csv', exist_ok=True)\n",
    "    \n",
    "    segments = [\n",
    "        ('5s', 5, False),\n",
    "        ('5s_overlap', 5, True),\n",
    "        ('10s', 10, False),\n",
    "        ('10s_overlap', 10, True),\n",
    "        ('15s', 15, False),\n",
    "        ('15s_overlap', 15, True)\n",
    "    ]\n",
    "    \n",
    "    for name, duration, overlap in segments:\n",
    "        mask = (df['segment_duration'] == duration) & (df['is_overlap'] == overlap)\n",
    "        df_seg = df[mask].copy()\n",
    "        df_seg.to_csv(f'final_dataset_csv/{name}.csv', index=False)\n",
    "        print(f\"Created {name}.csv with {len(df_seg)} samples\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    create_segmented_datasets()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
