{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "d01ae89c",
      "metadata": {
        "id": "d01ae89c"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Gaussian blur kernel for pyramids\n",
        "gaussian_kernel = (\n",
        "    np.array(\n",
        "        [\n",
        "            [1,  4,  6,  4, 1],\n",
        "            [4, 16, 24, 16, 4],\n",
        "            [6, 24, 36, 24, 6],\n",
        "            [4, 16, 24, 16, 4],\n",
        "            [1,  4,  6,  4, 1]\n",
        "        ]\n",
        "    ) / 256\n",
        ")\n",
        "\n",
        "# YIQ and RGB color space conversion matrices\n",
        "yiq_from_rgb = np.array([\n",
        "    [0.29900000,  0.58700000,  0.11400000],\n",
        "    [0.59590059, -0.27455667, -0.32134392],\n",
        "    [0.21153661, -0.52273617,  0.31119955]\n",
        "], dtype=np.float32)\n",
        "\n",
        "rgb_from_yiq = np.linalg.inv(yiq_from_rgb)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "81aef410",
      "metadata": {
        "id": "81aef410"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import tqdm\n",
        "\n",
        "\n",
        "def loadVideo(video_path):\n",
        "    image_sequence = []\n",
        "    video = cv2.VideoCapture(video_path)\n",
        "    fps = video.get(cv2.CAP_PROP_FPS)\n",
        "    while video.isOpened():\n",
        "        ret, frame = video.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        image_sequence.append(frame[:, :, ::-1])  # Convert BGR to RGB\n",
        "    video.release()\n",
        "    return np.asarray(image_sequence), fps\n",
        "\n",
        "def rgb2yiq(rgb_image):\n",
        "    return rgb_image.astype(np.float32) @ yiq_from_rgb.T\n",
        "\n",
        "def yiq2rgb(yiq_image):\n",
        "    return yiq_image.astype(np.float32) @ rgb_from_yiq.T\n",
        "\n",
        "def pyrDown(image, kernel):\n",
        "    return cv2.filter2D(image, -1, kernel)[::2, ::2]\n",
        "\n",
        "def pyrUp(image, kernel, dst_shape=None):\n",
        "    dst_height = image.shape[0] + 1\n",
        "    dst_width = image.shape[1] + 1\n",
        "    if dst_shape is not None:\n",
        "        dst_height -= (dst_shape[0] % image.shape[0] != 0)\n",
        "        dst_width -= (dst_shape[1] % image.shape[1] != 0)\n",
        "    upsampled_image = np.insert(image, np.arange(1, dst_height), 0, axis=0)\n",
        "    upsampled_image = np.insert(upsampled_image, np.arange(1, dst_width), 0, axis=1)\n",
        "    return cv2.filter2D(upsampled_image, -1, 4 * kernel)\n",
        "\n",
        "def idealTemporalBandpassFilter(images, fps, freq_range, axis=0):\n",
        "    fft = np.fft.fft(images, axis=axis)\n",
        "    frequencies = np.fft.fftfreq(images.shape[0], d=1.0 / fps)\n",
        "    low = (np.abs(frequencies - freq_range[0])).argmin()\n",
        "    high = (np.abs(frequencies - freq_range[1])).argmin()\n",
        "    fft[:low] = 0\n",
        "    fft[high:] = 0\n",
        "    return np.fft.ifft(fft, axis=0).real\n",
        "\n",
        "def reconstructGaussianImage(image, pyramid):\n",
        "    yiq = rgb2yiq(image) + pyramid\n",
        "    rgb = yiq2rgb(yiq)\n",
        "    return np.clip(rgb, 0, 255).astype(np.uint8)\n",
        "\n",
        "def reconstructLaplacianImage(image, pyramid, kernel):\n",
        "    reconstructed_image = rgb2yiq(image)\n",
        "    for level in range(1, pyramid.shape[0] - 1):\n",
        "        tmp = pyramid[level]\n",
        "        for curr_level in range(level):\n",
        "            tmp = pyrUp(tmp, kernel, pyramid[level - curr_level - 1].shape[:2])\n",
        "        reconstructed_image += tmp.astype(np.float32)\n",
        "    return np.clip(yiq2rgb(reconstructed_image), 0, 255).astype(np.uint8)\n",
        "\n",
        "def getGaussianOutputVideo(original_images, filtered_images):\n",
        "    video = np.zeros_like(original_images)\n",
        "    for i in tqdm.tqdm(range(filtered_images.shape[0]), desc=\"Reconstructing Video\", ascii=True):\n",
        "        video[i] = reconstructGaussianImage(original_images[i], filtered_images[i])\n",
        "    return video\n",
        "\n",
        "def getLaplacianOutputVideo(original_images, filtered_images, kernel):\n",
        "    video = np.zeros_like(original_images)\n",
        "    for i in tqdm.tqdm(range(original_images.shape[0]), desc=\"Reconstructing Video\", ascii=True):\n",
        "        video[i] = reconstructLaplacianImage(original_images[i], filtered_images[i], kernel)\n",
        "    return video\n",
        "\n",
        "def saveVideo(video, saving_path, fps):\n",
        "    height, width = video[0].shape[:2]\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'XVID')  # Better for .avi output\n",
        "    writer = cv2.VideoWriter(saving_path, fourcc, fps, (width, height))\n",
        "\n",
        "    for frame in tqdm.tqdm(video, desc=\"Saving Video\", ascii=True):\n",
        "        bgr = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)  # Convert RGB to BGR\n",
        "        writer.write(bgr)\n",
        "\n",
        "    writer.release()\n",
        "    print(f\"EVM video saved to {saving_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "c039fe2b",
      "metadata": {
        "id": "c039fe2b"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tqdm\n",
        "\n",
        "\n",
        "def generateGaussianPyramid(image, kernel, level):\n",
        "    image_shape = [image.shape[:2]]\n",
        "    downsampled_image = image.copy()\n",
        "    for _ in range(level):\n",
        "        downsampled_image = pyrDown(downsampled_image, kernel)\n",
        "        image_shape.append(downsampled_image.shape[:2])\n",
        "    gaussian_pyramid = downsampled_image\n",
        "    for curr_level in range(level):\n",
        "        gaussian_pyramid = pyrUp(\n",
        "            gaussian_pyramid,\n",
        "            kernel=kernel,\n",
        "            dst_shape=image_shape[level - curr_level - 1]\n",
        "        )\n",
        "    return gaussian_pyramid\n",
        "\n",
        "def getGaussianPyramids(images, kernel, level):\n",
        "    gaussian_pyramids = np.zeros_like(images, dtype=np.float32)\n",
        "    for i in tqdm.tqdm(range(images.shape[0]), desc=\"Gaussian Pyramids Generation\", ascii=True):\n",
        "        yiq_image = rgb2yiq(images[i])\n",
        "        gaussian_pyramids[i] = generateGaussianPyramid(yiq_image, kernel, level)\n",
        "    return gaussian_pyramids\n",
        "\n",
        "def filterGaussianPyramids(pyramids, fps, freq_range, alpha, attenuation):\n",
        "    filtered_pyramids = idealTemporalBandpassFilter(\n",
        "        images=pyramids,\n",
        "        fps=fps,\n",
        "        freq_range=freq_range\n",
        "    ).astype(np.float32)\n",
        "    filtered_pyramids *= alpha\n",
        "    filtered_pyramids[:, :, :, 1:] *= attenuation\n",
        "    return filtered_pyramids\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "a9eec384",
      "metadata": {
        "id": "a9eec384"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tqdm\n",
        "from scipy.signal import butter, lfilter\n",
        "\n",
        "def generateLaplacianPyramid(image, kernel, level):\n",
        "    laplacian_pyramid = []\n",
        "    prev_image = image.copy()\n",
        "    for _ in range(level):\n",
        "        downsampled = pyrDown(prev_image, kernel)\n",
        "        upsampled = pyrUp(downsampled, kernel, dst_shape=prev_image.shape[:2])\n",
        "        laplacian = prev_image - upsampled\n",
        "        laplacian_pyramid.append(laplacian)\n",
        "        prev_image = downsampled\n",
        "    return laplacian_pyramid\n",
        "\n",
        "def getLaplacianPyramids(images, kernel, level):\n",
        "    laplacian_pyramids = []\n",
        "    for image in tqdm.tqdm(images, desc=\"Laplacian Pyramids Generation\", ascii=True):\n",
        "        yiq_image = rgb2yiq(image)\n",
        "        pyramid = generateLaplacianPyramid(yiq_image, kernel, level)\n",
        "        laplacian_pyramids.append(pyramid)\n",
        "    return np.asarray(laplacian_pyramids, dtype='object')\n",
        "\n",
        "def filterLaplacianPyramids(pyramids, level, fps, freq_range, alpha, lambda_cutoff, attenuation):\n",
        "    filtered = np.zeros_like(pyramids)\n",
        "    delta = lambda_cutoff / (8 * (1 + alpha))\n",
        "    b_low, a_low = butter(1, freq_range[0], btype='low', fs=fps)\n",
        "    b_high, a_high = butter(1, freq_range[1], btype='low', fs=fps)\n",
        "    lowpass = pyramids[0]\n",
        "    highpass = pyramids[0]\n",
        "    filtered[0] = pyramids[0]\n",
        "    for i in tqdm.tqdm(range(1, pyramids.shape[0]), desc=\"Laplacian Pyramids Filtering\", ascii=True):\n",
        "        lowpass = (-a_low[1] * lowpass + b_low[0] * pyramids[i] + b_low[1] * pyramids[i - 1]) / a_low[0]\n",
        "        highpass = (-a_high[1] * highpass + b_high[0] * pyramids[i] + b_high[1] * pyramids[i - 1]) / a_high[0]\n",
        "        filtered[i] = highpass - lowpass\n",
        "        for lvl in range(1, level - 1):\n",
        "            height, width, _ = filtered[i, lvl].shape\n",
        "            lambd = np.sqrt(height ** 2 + width ** 2)\n",
        "            new_alpha = (lambd / (8 * delta)) - 1\n",
        "            filtered[i, lvl] *= min(alpha, new_alpha)\n",
        "            filtered[i, lvl][:, :, 1:] *= attenuation\n",
        "    return filtered\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "ab811482",
      "metadata": {
        "id": "ab811482"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def gaussian_evm(images, fps, kernel, level, alpha, freq_range, attenuation):\n",
        "    pyramids = getGaussianPyramids(images, kernel, level)\n",
        "    print(\"Gaussian Pyramids Filtering...\")\n",
        "    filtered = filterGaussianPyramids(pyramids, fps, freq_range, alpha, attenuation)\n",
        "    print(\"Finished filtering!\")\n",
        "    output = getGaussianOutputVideo(original_images=images, filtered_images=filtered)\n",
        "    return output\n",
        "\n",
        "def laplacian_evm(images, fps, kernel, level, alpha, lambda_cutoff, freq_range, attenuation):\n",
        "    pyramids = getLaplacianPyramids(images, kernel, level)\n",
        "    filtered = filterLaplacianPyramids(pyramids, level, fps, freq_range, alpha, lambda_cutoff, attenuation)\n",
        "    output = getLaplacianOutputVideo(original_images=images, filtered_images=filtered, kernel=kernel)\n",
        "    return output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "862a325c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "862a325c",
        "outputId": "f3956f31-fc7d-4e79-d187-075c553ab937"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded video with 2819 frames at 30.00 FPS\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Laplacian Pyramids Generation: 100%|##########| 2819/2819 [00:12<00:00, 227.10it/s]\n",
            "Laplacian Pyramids Filtering: 100%|##########| 2818/2818 [00:32<00:00, 87.96it/s] \n",
            "Reconstructing Video: 100%|##########| 2819/2819 [00:27<00:00, 103.99it/s]\n",
            "Saving Video: 100%|##########| 2819/2819 [00:01<00:00, 1471.73it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EVM video saved to evm_videos/Unbalance_weight/front_evm.avi\n",
            "Saved output video to evm_videos/Unbalance_weight/front_evm.avi\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# === Provide the path to your video ===\n",
        "video_path = \"merged_preprocessed_videos/Unbalance_weight/front.avi\"  # <-- Replace with your actual video filename or full path\n",
        "\n",
        "# === Load the video frames and fps ===\n",
        "images, fps = loadVideo(video_path)\n",
        "print(f\"Loaded video with {len(images)} frames at {fps:.2f} FPS\")\n",
        "\n",
        "# === Define parameters ===\n",
        "level = 5\n",
        "alpha = 100\n",
        "freq_range = [0.1, 2.0]\n",
        "attenuation = 5\n",
        "lambda_cutoff = 500  # Only used in Laplacian\n",
        "\n",
        "# === Choose method ===\n",
        "mode = \"laplacian\"  # or \"laplacian\"\n",
        "\n",
        "# === Run selected EVM ===\n",
        "if mode == \"gaussian\":\n",
        "    output_video = gaussian_evm(\n",
        "        images=images,\n",
        "        fps=fps,\n",
        "        kernel=gaussian_kernel,\n",
        "        level=level,\n",
        "        alpha=alpha,\n",
        "        freq_range=freq_range,\n",
        "        attenuation=attenuation\n",
        "    )\n",
        "else:\n",
        "    output_video = laplacian_evm(\n",
        "        images=images,\n",
        "        fps=fps,\n",
        "        kernel=gaussian_kernel,\n",
        "        level=level,\n",
        "        alpha=alpha,\n",
        "        lambda_cutoff=lambda_cutoff,\n",
        "        freq_range=freq_range,\n",
        "        attenuation=attenuation\n",
        "    )\n",
        "\n",
        "# === Save output ===\n",
        "output_path = \"evm_videos/Unbalance_weight/front_evm.avi\"\n",
        "saveVideo(output_video, output_path, fps)\n",
        "print(f\"Saved output video to {output_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "d77c261b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded video with 2819 frames at 30.00 FPS\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Laplacian Pyramids Generation: 100%|##########| 2819/2819 [00:22<00:00, 126.32it/s]\n",
            "Laplacian Pyramids Filtering: 100%|##########| 2818/2818 [00:15<00:00, 182.32it/s]\n",
            "Reconstructing Video: 100%|##########| 2819/2819 [00:24<00:00, 116.20it/s]\n",
            "Saving Video: 100%|##########| 2819/2819 [00:01<00:00, 2062.62it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EVM video saved to evm_videos/Unbalance_weight/angle_evm.avi\n",
            "Saved output video to evm_videos/Unbalance_weight/angle_evm.avi\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# === Provide the path to your video ===\n",
        "video_path = \"merged_preprocessed_videos/Unbalance_weight/angle.avi\"  # <-- Replace with your actual video filename or full path\n",
        "\n",
        "# === Load the video frames and fps ===\n",
        "images, fps = loadVideo(video_path)\n",
        "print(f\"Loaded video with {len(images)} frames at {fps:.2f} FPS\")\n",
        "\n",
        "# === Define parameters ===\n",
        "level = 5\n",
        "alpha = 100\n",
        "freq_range = [0.1, 2.0]\n",
        "attenuation = 5\n",
        "lambda_cutoff = 500  # Only used in Laplacian\n",
        "\n",
        "# === Choose method ===\n",
        "mode = \"laplacian\"  # or \"laplacian\"\n",
        "\n",
        "\n",
        "# === Run selected EVM ===\n",
        "if mode == \"gaussian\":\n",
        "    output_video = gaussian_evm(\n",
        "        images=images,\n",
        "        fps=fps,\n",
        "        kernel=gaussian_kernel,\n",
        "        level=level,\n",
        "        alpha=alpha,\n",
        "        freq_range=freq_range,\n",
        "        attenuation=attenuation\n",
        "    )\n",
        "else:\n",
        "    output_video = laplacian_evm(\n",
        "        images=images,\n",
        "        fps=fps,\n",
        "        kernel=gaussian_kernel,\n",
        "        level=level,\n",
        "        alpha=alpha,\n",
        "        lambda_cutoff=lambda_cutoff,\n",
        "        freq_range=freq_range,\n",
        "        attenuation=attenuation\n",
        "    )\n",
        "\n",
        "# === Save output ===\n",
        "output_path = \"evm_videos/Unbalance_weight/angle_evm.avi\"\n",
        "saveVideo(output_video, output_path, fps)\n",
        "print(f\"Saved output video to {output_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "66b4cfca",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded video with 2819 frames at 30.00 FPS\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Laplacian Pyramids Generation: 100%|##########| 2819/2819 [00:13<00:00, 215.38it/s]\n",
            "Laplacian Pyramids Filtering: 100%|##########| 2818/2818 [00:15<00:00, 180.95it/s]\n",
            "Reconstructing Video: 100%|##########| 2819/2819 [00:23<00:00, 119.95it/s]\n",
            "Saving Video: 100%|##########| 2819/2819 [00:01<00:00, 2076.04it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EVM video saved to evm_videos/Bearing_fault/front_evm.avi\n",
            "Saved output video to evm_videos/Bearing_fault/front_evm.avi\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# === Provide the path to your video ===\n",
        "video_path = \"merged_preprocessed_videos/Bearing_fault/front.avi\"  # <-- Replace with your actual video filename or full path\n",
        "\n",
        "# === Load the video frames and fps ===\n",
        "images, fps = loadVideo(video_path)\n",
        "print(f\"Loaded video with {len(images)} frames at {fps:.2f} FPS\")\n",
        "\n",
        "# === Define parameters ===\n",
        "level = 5\n",
        "alpha = 100\n",
        "freq_range = [0.1, 2.0]\n",
        "attenuation = 5\n",
        "lambda_cutoff = 500  # Only used in Laplacian\n",
        "\n",
        "# === Choose method ===\n",
        "mode = \"laplacian\"  # or \"laplacian\"\n",
        "\n",
        "\n",
        "# === Run selected EVM ===\n",
        "if mode == \"gaussian\":\n",
        "    output_video = gaussian_evm(\n",
        "        images=images,\n",
        "        fps=fps,\n",
        "        kernel=gaussian_kernel,\n",
        "        level=level,\n",
        "        alpha=alpha,\n",
        "        freq_range=freq_range,\n",
        "        attenuation=attenuation\n",
        "    )\n",
        "else:\n",
        "    output_video = laplacian_evm(\n",
        "        images=images,\n",
        "        fps=fps,\n",
        "        kernel=gaussian_kernel,\n",
        "        level=level,\n",
        "        alpha=alpha,\n",
        "        lambda_cutoff=lambda_cutoff,\n",
        "        freq_range=freq_range,\n",
        "        attenuation=attenuation\n",
        "    )\n",
        "\n",
        "# === Save output ===\n",
        "output_path = \"evm_videos/Bearing_fault/front_evm.avi\"\n",
        "saveVideo(output_video, output_path, fps)\n",
        "print(f\"Saved output video to {output_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "0a528d99",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded video with 2819 frames at 30.00 FPS\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Laplacian Pyramids Generation: 100%|##########| 2819/2819 [00:11<00:00, 251.03it/s]\n",
            "Laplacian Pyramids Filtering: 100%|##########| 2818/2818 [00:16<00:00, 168.87it/s]\n",
            "Reconstructing Video: 100%|##########| 2819/2819 [00:23<00:00, 122.16it/s]\n",
            "Saving Video: 100%|##########| 2819/2819 [00:01<00:00, 1944.41it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EVM video saved to evm_videos/Bearing_fault/angle_evm.avi\n",
            "Saved output video to evm_videos/Bearing_fault/angle_evm.avi\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# === Provide the path to your video ===\n",
        "video_path = \"merged_preprocessed_videos/Bearing_fault/angle.avi\"  # <-- Replace with your actual video filename or full path\n",
        "\n",
        "# === Load the video frames and fps ===\n",
        "images, fps = loadVideo(video_path)\n",
        "print(f\"Loaded video with {len(images)} frames at {fps:.2f} FPS\")\n",
        "\n",
        "# === Define parameters ===\n",
        "level = 5\n",
        "alpha = 100\n",
        "freq_range = [0.1, 2.0]\n",
        "attenuation = 5\n",
        "lambda_cutoff = 500  # Only used in Laplacian\n",
        "\n",
        "# === Choose method ===\n",
        "mode = \"laplacian\"  # or \"laplacian\"\n",
        "\n",
        "\n",
        "# === Run selected EVM ===\n",
        "if mode == \"gaussian\":\n",
        "    output_video = gaussian_evm(\n",
        "        images=images,\n",
        "        fps=fps,\n",
        "        kernel=gaussian_kernel,\n",
        "        level=level,\n",
        "        alpha=alpha,\n",
        "        freq_range=freq_range,\n",
        "        attenuation=attenuation\n",
        "    )\n",
        "else:\n",
        "    output_video = laplacian_evm(\n",
        "        images=images,\n",
        "        fps=fps,\n",
        "        kernel=gaussian_kernel,\n",
        "        level=level,\n",
        "        alpha=alpha,\n",
        "        lambda_cutoff=lambda_cutoff,\n",
        "        freq_range=freq_range,\n",
        "        attenuation=attenuation\n",
        "    )\n",
        "\n",
        "# === Save output ===\n",
        "output_path = \"evm_videos/Bearing_fault/angle_evm.avi\"\n",
        "saveVideo(output_video, output_path, fps)\n",
        "print(f\"Saved output video to {output_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "e5284bec",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded video with 2819 frames at 30.00 FPS\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Laplacian Pyramids Generation: 100%|##########| 2819/2819 [00:11<00:00, 242.15it/s]\n",
            "Laplacian Pyramids Filtering: 100%|##########| 2818/2818 [00:15<00:00, 184.33it/s]\n",
            "Reconstructing Video: 100%|##########| 2819/2819 [00:22<00:00, 123.25it/s]\n",
            "Saving Video: 100%|##########| 2819/2819 [00:01<00:00, 2226.20it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EVM video saved to evm_videos/Normal_state/front_evm.avi\n",
            "Saved output video to evm_videos/Normal_state/front_evm.avi\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# === Provide the path to your video ===\n",
        "video_path = \"merged_preprocessed_videos/Normal_state/front.avi\"  # <-- Replace with your actual video filename or full path\n",
        "\n",
        "# === Load the video frames and fps ===\n",
        "images, fps = loadVideo(video_path)\n",
        "print(f\"Loaded video with {len(images)} frames at {fps:.2f} FPS\")\n",
        "\n",
        "# === Define parameters ===\n",
        "level = 5\n",
        "alpha = 100\n",
        "freq_range = [0.1, 2.0]\n",
        "attenuation = 5\n",
        "lambda_cutoff = 500  # Only used in Laplacian\n",
        "\n",
        "# === Choose method ===\n",
        "mode = \"laplacian\"  # or \"laplacian\"\n",
        "\n",
        "\n",
        "# === Run selected EVM ===\n",
        "if mode == \"gaussian\":\n",
        "    output_video = gaussian_evm(\n",
        "        images=images,\n",
        "        fps=fps,\n",
        "        kernel=gaussian_kernel,\n",
        "        level=level,\n",
        "        alpha=alpha,\n",
        "        freq_range=freq_range,\n",
        "        attenuation=attenuation\n",
        "    )\n",
        "else:\n",
        "    output_video = laplacian_evm(\n",
        "        images=images,\n",
        "        fps=fps,\n",
        "        kernel=gaussian_kernel,\n",
        "        level=level,\n",
        "        alpha=alpha,\n",
        "        lambda_cutoff=lambda_cutoff,\n",
        "        freq_range=freq_range,\n",
        "        attenuation=attenuation\n",
        "    )\n",
        "\n",
        "# === Save output ===\n",
        "output_path = \"evm_videos/Normal_state/front_evm.avi\"\n",
        "saveVideo(output_video, output_path, fps)\n",
        "print(f\"Saved output video to {output_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "04cdfcab",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded video with 2819 frames at 30.00 FPS\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Laplacian Pyramids Generation: 100%|##########| 2819/2819 [00:12<00:00, 226.21it/s]\n",
            "Laplacian Pyramids Filtering: 100%|##########| 2818/2818 [00:16<00:00, 172.06it/s]\n",
            "Reconstructing Video: 100%|##########| 2819/2819 [00:25<00:00, 112.60it/s]\n",
            "Saving Video: 100%|##########| 2819/2819 [00:01<00:00, 2016.87it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EVM video saved to evm_videos/Normal_state/angle_evm.avi\n",
            "Saved output video to evm_videos/Normal_state/angle_evm.avi\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# === Provide the path to your video ===\n",
        "video_path = \"merged_preprocessed_videos/Normal_state/angle.avi\"  # <-- Replace with your actual video filename or full path\n",
        "\n",
        "# === Load the video frames and fps ===\n",
        "images, fps = loadVideo(video_path)\n",
        "print(f\"Loaded video with {len(images)} frames at {fps:.2f} FPS\")\n",
        "\n",
        "# === Define parameters ===\n",
        "level = 5\n",
        "alpha = 100\n",
        "freq_range = [0.1, 2.0]\n",
        "attenuation = 5\n",
        "lambda_cutoff = 500  # Only used in Laplacian\n",
        "# === Choose method ===\n",
        "mode = \"laplacian\"  # or \"laplacian\"\n",
        "\n",
        "\n",
        "# === Run selected EVM ===\n",
        "if mode == \"gaussian\":\n",
        "    output_video = gaussian_evm(\n",
        "        images=images,\n",
        "        fps=fps,\n",
        "        kernel=gaussian_kernel,\n",
        "        level=level,\n",
        "        alpha=alpha,\n",
        "        freq_range=freq_range,\n",
        "        attenuation=attenuation\n",
        "    )\n",
        "else:\n",
        "    output_video = laplacian_evm(\n",
        "        images=images,\n",
        "        fps=fps,\n",
        "        kernel=gaussian_kernel,\n",
        "        level=level,\n",
        "        alpha=alpha,\n",
        "        lambda_cutoff=lambda_cutoff,\n",
        "        freq_range=freq_range,\n",
        "        attenuation=attenuation\n",
        "    )\n",
        "\n",
        "# === Save output ===\n",
        "output_path = \"evm_videos/Normal_state/angle_evm.avi\"\n",
        "saveVideo(output_video, output_path, fps)\n",
        "print(f\"Saved output video to {output_path}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
